system:
  name: "SOCIA"
  version: "0.1.0"
  description: "Simulation Orchestration for City Intelligence and Agents"

llm:
  provider: "openai"  # options: openai, gemini, anthropic, llama, etc.

# Available LLM providers configuration
llm_providers:
  openai:
    model: "gpt-4.1"  # options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, gpt-4.1-2025-04-14, etc.
    temperature: 0.7
    max_tokens: 10000
    api_key: ""  # set via environment variable or keys.py
    timeout: 60  # seconds
  gemini:
    model: "models/gemini-2.5-flash-preview-04-17"  # Must use full path including "models/" prefix
    temperature: 0.7
    max_tokens: 8192
    api_key: ""  # set via environment variable or keys.py
    timeout: 60  # seconds
  anthropic:
    model: "claude-3-opus-20240229"
    temperature: 0.7
    max_tokens: 4000
    api_key: ""
    timeout: 60  # seconds
  llama:
    model_path: "./models/llama-2-13b"
    temperature: 0.7
    max_tokens: 2048
    timeout: 120  # seconds

agents:
  task_understanding:
    enabled: true
    prompt_template: "templates/task_understanding_prompt.txt"
    output_format: "json"
  
  data_analysis:
    enabled: true
    prompt_template: "templates/data_analysis_prompt.txt"
    output_format: "json"
    supported_data_types: ["csv", "json", "geojson", "shapefile"]
  
  model_planning:
    enabled: true
    prompt_template: "templates/model_planning_prompt.txt"
    output_format: "json"
    available_models: ["gravity", "agent_based", "sir", "network", "system_dynamics"]
  
  code_generation:
    enabled: true
    prompt_template: "templates/code_generation_prompt.txt"
    output_format: "python"
    code_style: "pep8"
    
  code_verification:
    enabled: true
    prompt_template: "templates/code_verification_prompt.txt"
    output_format: "json"
    run_tests: true
    output_dir: "output/verification"
    
  simulation_execution:
    enabled: true
    prompt_template: "templates/simulation_execution_prompt.txt"
    output_format: "json"
    sandbox: "local"  # options: local, docker, cloud
    timeout: 300  # seconds
    
  result_evaluation:
    enabled: true
    prompt_template: "templates/result_evaluation_prompt.txt"
    output_format: "json"
    metrics: ["mse", "mae", "correlation", "distribution_kl", "dard"]
    
  feedback_generation:
    enabled: true
    prompt_template: "templates/feedback_generation_prompt.txt"
    output_format: "json"
    
  iteration_control:
    enabled: true
    prompt_template: "templates/iteration_control_prompt.txt"
    output_format: "json"
    convergence_threshold: 0.05
    
workflow:
  max_iterations: 3
  parallel_execution: false
  save_intermediate_results: true
  
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "socia.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
output:
  save_format: ["python", "json", "visualization"]
  visualization_types: ["agent_trajectories", "heatmaps", "network_graphs", "timeseries"] 